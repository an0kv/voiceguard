# VoiceGuard Desktop

Настольное приложение для локальной детекции синтетического/поддельного голоса (TTS / voice cloning) в аудиофайлах и в реальном времени (микрофон и системный звук/созвоны).

В этом репозитории — MVP-реализация на **Python + PySide6**, с подключаемым инференсом (**ONNX Runtime**) и рабочим fallback-детектором (эвристика), чтобы приложение запускалось без весов модели.

## Как пользоваться (для обычного пользователя)

- Вкладка **Файл**: выберите/перетащите аудиофайл → получите оценку **вероятности, что голос сгенерирован ИИ**, график по времени и список подозрительных сегментов.
- Вкладка **Live**: выберите источник (**Микрофон** или **Системный звук**) → нажмите **Старт** → приложение обновляет оценку в реальном времени и показывает предупреждение, если вероятность держится выше порога. Для созвонов доступен режим **Фокус на речи** (фильтр + шумоподавление) и профили (Созвон/Шум/Студия).

Примечание про системный звук:

- Windows: используется **WASAPI loopback**, достаточно выбрать нужное устройство вывода.
- macOS/Linux: нужен виртуальный loopback (BlackHole/Soundflower/PulseAudio Monitor) и выбор соответствующего устройства.
- Для изоляции конкретного приложения (Zoom/Discord) направьте его звук на отдельное виртуальное устройство и выберите его в Live‑источнике.

Важно: это **вероятностная** оценка, не 100% доказательство. На точность влияют шум, качество микрофона, VoIP/кодеки и пересжатие.

## Быстрый старт (dev)

1) Создать окружение и установить зависимости:

```bash
python3 -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate
pip install -r requirements.txt
```

2) Запуск:

```bash
python3 app.py
```

## Android прототип

См. `android/README.md` — там минимальный прототип для live‑детекции на Android (микрофон и AudioPlaybackCapture).

## Примечания по аудиоформатам

- Для `.wav/.flac` достаточно `soundfile`.
- Для `.mp3` может понадобиться `ffmpeg` (и `pydub`), если `soundfile` не умеет декодировать MP3 в вашей сборке `libsndfile`.

## Подключение ONNX-модели

По умолчанию используется **демо‑режим (эвристика)**. Для максимальной точности подключите ML‑модель (ONNX):

1) Положите модель в `models/voiceguard.onnx` (или измените путь в `config.yaml`).
2) В `config.yaml` установите `model.backend: onnx` (или оставьте `auto`, тогда приложение само включит ONNX при наличии модели).

Ожидаемый интерфейс модели (MVP):

- вход: `log_mel` формы `(1, n_mels, n_frames)` `float32`
- выход:
  - либо один выход `p_fake` в диапазоне `[0..1]`,
  - либо два класса/logits (реал/фейк), из которых берётся вероятность фейка.

## Подключение HuggingFace‑модели (самый простой путь к высокой точности)

Этот вариант скачивает готовую модель антиспуфинга/детекции дипфейков и хранит её локально (в папке `models/`, она в `.gitignore`).

1) Установите ML‑зависимости:

```bash
pip install -r requirements-ml.txt
```

2) Скачайте модель‑снапшот (по умолчанию `Shahzaib-Arshad/deepfake_audio_detection`):

```bash
python3 scripts/download_hf_model.py
```

3) Проверьте `config.yaml`:

- `model.backend: auto` (или `hf`)
- `model.hf_local_dir: models/hf_shahzaib_deepfake`

## Примечание про Python/ONNX Runtime

`onnxruntime` может быть недоступен для некоторых версий Python (например, 3.14). В таком случае приложение автоматически откатится в демо‑режим (эвристика).

---

# VoiceGuard Desktop — документация проекта (README + mini‑SRS)

## 1) Назначение и цель

**VoiceGuard Desktop** — настольное приложение для **детекции синтетического/поддельного голоса** (TTS, voice cloning) в:

* **аудиофайлах** (offline‑проверка),
* **аудиопотоке в реальном времени** (микрофон / loopback системного звука).

Цель: снизить риск мошенничества (anti‑fraud) и повысить доверие к голосовым коммуникациям, **без записи/отправки аудио в облако** (по умолчанию всё локально).

---

## 2) Основные сценарии использования (Use Cases)

### UC‑1: Проверка аудиофайла

Пользователь перетаскивает `.wav/.mp3/.flac` → приложение показывает:

* вероятность синтетики (0–100%),
* “уверенность” модели,
* объяснения (ключевые признаки/сегменты, где подозрительно).

### UC‑2: Реальное время — микрофон

Пользователь включает режим “Live (Mic)” → приложение оценивает поток **в окнах по 1–2 секунды**, строит таймлайн, предупреждает при росте вероятности синтетики.

### UC‑3: Реальное время — звук системы (Loopback)

Пользователь включает “Live → Системный звук” → анализируются входящие голосовые сообщения/созвоны, воспроизводимые на ПК (технически: loopback‑захват).

---

## 3) Нефункциональные требования

* **Локальная обработка** аудио по умолчанию (privacy by default).
* **Задержка** в live‑режиме: целиться в ≤ 300–500 ms на окно (зависит от модели/железа).
* **Кроссплатформенность** (желательно): Windows 10/11, macOS, Linux.
* **Объяснимость**: помимо числа — простые причины/индикаторы.
* **Безопасность**: приложение не должно хранить “сырое” аудио без явного согласия.

---

## 4) Ограничения и честные оговорки

* Нельзя “на 100%” отличить любой дипфейк: качество генераторов растёт. Поэтому выдаём **оценку вероятности + уверенность + условия применимости**.
* Результат зависит от **кодеков, шумов, микрофона**, пересжатия (Zoom/Discord) и т.д.
* Приложение **не предназначено** для слежки/перехвата: только анализ выбранного пользователем источника.

---

## 5) Архитектура (High‑level)

### 5.1 Компоненты

1. **GUI (Frontend)**
   * окно, настройки, графики, экспорт отчёта
2. **Audio I/O слой**
   * захват аудио (mic/loopback), ресемплинг, VAD/сегментация
3. **Inference Engine**
   * загрузка модели (ONNX / TorchScript), инференс по окнам
4. **Feature/Explain Layer**
   * дополнительные признаки для интерпретации
5. **Storage/Telemetry (локально)**
   * хранение только метаданных/результатов (опционально)
6. **Evaluation Toolkit**
   * метрики ROC‑AUC/EER, отчёты, robustness‑тесты

### 5.2 Поток данных

Audio source → Preprocess (mono, 16 kHz, normalize) → Windowing (например, 1.0 s с шагом 0.25 s) → Model inference → Smoothing (EMA/median) → UI (probability timeline + alerts)

---

## 6) Выбор стека (рекомендация для MVP)

**Вариант A:** Python + PySide6 (Qt)

* GUI: PySide6
* Audio capture: sounddevice
* ML inference: ONNX Runtime (опционально)
* DSP: numpy/scipy
* Packaging: PyInstaller / py2app / AppImage

---

## 11) Конфигурация

См. `config.yaml`.

---

## 12) Безопасность и приватность

* По умолчанию **не сохранять аудио**.
* В отчёты писать только метаданные и агрегаты.
* Если пользователь включает сохранение — явное предупреждение и выбор папки.
* Логи без персональных данных.
